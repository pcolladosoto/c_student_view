\documentclass[12pt]{book}

\usepackage{minted}

\begin{document}

    \chapter{C Operators and Preference}

        We have already seen the basic building blocks of C: variables and their data types. Now, the question is how we can "play" with them. "Playing" is just being able to combine these elements in meaningful ways.

        I once had a teacher who told me some of the best programmers he knew were not computer scientists, but mathematicians. I believe this chapter shows why that may be the case. Mathematicians don't see every number in the same way. Some of them are \textbf{REAL} numbers, some of them are \textbf{Imaginary}, some are just \textbf{INTegers}... and the rules to combine them are sometimes different. See, in math everything has a strict type. The same goes for C! This is what makes C a \textit{Strongly Typed Language}. Whenever we declare a variable we must declare its type. This may seem cumbersome, but I believe it makes programs way clearer on the long run.

        The good news is that in C we only have \textbf{REAL} numbers, so the only rules we have to dust off are those of basic arithmetics... for now!

        \section{Basic arithmetic operators}

            As most of the variables we have dealt with are representations of numbers, be it reals or integers, we will first focus on basic arithmetics. We will present a piece of code showing them in action.

            \begin{minted}{c}
                int a = 3 + 5;  // a = 8
                int b = 10 - 5; // b = 5
                int c = 4 * 3;  // c = 12
                int d = 15 / 5; // d = 3
            \end{minted}

            We then see what each symbol stands for:

            \begin{itemize}
                \item Addition: +
                \item Subtraction: -
                \item Multiplication: *
                \item Division: /
            \end{itemize}

            Let's take it up a notch by combining several operations. This works like everyday math, so give it a try. This may actually sound familiar, as questions like the one below are pretty common on social media \dots

            \begin{minted}{c}
                int a = 2 + (3 + 1) / 4;     // a = ?
                int b = (4 + 3 * 2) / 5 * 6; // b = ?
            \end{minted}

            You may remember how parenthesis alter the priority of the operators with them having the highest precedence. Taking that into account yields: $a = 3; b = 12$.

            \subsection{Truncation}

            Up to this point everything seems to be quite normal. Anybody could know the answers to the above. The avid reader will have noticed how \textbf{EVERY} computation shown above yielded integers. Notice how all the variables storing those results are integers too. This leads to a rather scary question. What would $a$ end up being here?

            \begin{minted}{c}
                int a = 4.5 + 5;
            \end{minted}

            You may be tempted to say that $a = 9.5$. But if $a$ is an integer \dots How can it hold a decimal number? The short answer is that it cannot and so it will drop the entire decimal part. Thus, $a = 9$. This phenomena is what we know as \textbf{truncation}.

            Imagine you had a giant pot of ramen (japanese noodles) but your bowls are much smaller. You would be forced to only serve as much as you can in the bowls, but that would't be all the delicious ramen you have cooked. You would then be truncating the big pot to your bowl's size.

            C is doing the same thing under the hood. Your program is being forced to fit a \textit{float} into an \textit{int}. As this is impossible, the compiler will fit as much as it can, only the integer part.

            We won't wo any further with this matter here, but you can find an appendix going through the basic numrical representations used in computers. Just to tease your curiosity, think about how we can represent a decimal number when all we have are bits; we don't have a comma (dt for our american readers) anywhere...

            \subsection{Looping, (a.k.a Overflowing)}

            Time for yet another scary question. What would $a$ and $b$ end up being here:

            \begin{minted}{c}
                unsigned char a = 256;
                unsigned char b = 300;
            \end{minted}

            If you recall from chapter 1, the values of an \textit{unsigned char} are within the $[0, 255]$ interval. Then, what happens when we assign a value outside of said interval? \\

            The short answer is that what we are assigning is not the value $x$ we provide, but $x\ \% \ 256$ in this case. Here, \% stands for modulo. We will see it later on in this same chapter, so don't worry too much about it. \\

            In chapter 1 we said that an \textit{unsigned char} is 1 byte long. Talking now "in" hex numbers we see that comprehends the interval $[0x0, 0xFF]$. If you don't feel comfortable enough with hex numbers please refer to the annex on numbering systems. \\

            Think of the compiler as "only looking at this last byte", the only one it cares about. Now, what is the hex notation of $256$? That would be $0x100$. What is the last byte (LSByte) now? That's right, its a good ol' $0$! \\

            If we assign $256$ to an \textit{unsigned char} we will then be "looping" through all the possible numbers and begin from the beginning once more. This is sometimes regarded as "overflowing" the variable. We assigned a value that's too large for it \dots The compiler will ususally warn you about this situation, so try to keep an eye out for it. \\

            What would $b$ be in the end? Following the same logic we can see how: $300 = 256 + 44$, so we will overflow $b$ once and have a $44$ remaining. Hence, $b = 44$! \\

            Another way to look at it is to see how $300 = 0x12C$. The third digit in the hex number is $1$, we have "provoked" $1$ overflow. The remaining number is $0x2C$, which happens to be, no surprise, $44$!. Now, how many overflows will we provoke if the number we try to store in $a$ is $0x30A$. That's correct, $3$. \\

            Finally, even though we haven't seen the modulo operation yet, you should "believe" that $300 \% 256$ is indeed $44$.

            Now you may be wandering whether this happens for \textbf{int}s too. The case with this bigger data type is exactly the same. The only thing is that, as \textbf{int}s are $4$ bytes long their possible values are in the range $[0x00000000,\ 0xFFFFFFFF]$. Then again if we try to assign the value $0x10000000A$ to an \textbf{int} we can assure that we have provoked $1$ overflow (look at the LSB) and that the value we will \textit{truncate} it to is $0xA$.

            The last question we may have is wheter this is true for \textbf{float}s as well and the answer is kind of \dots Due to the way real numbers are represented internally we prefer to talk about their "precision" which is fancy for how many decimals can they hold? We will treat this case in the annex as it is more a matter of Computer Architecture than pure programming.

            All in all we can see how dealing with data types that can hold a discrete set of values tends to "muddy" up things a bit... These problems are not that common when dealing with "academic" programming like the one we inted to cover here. It is a matter of importance, however, when programming digital electronic systems that need to take into account the number of edges in a clock signal or when we have to keep track of how may packets are arriving to a given system. This last point is a witness of how fast computational speeds has eveolved. When dealing with a topic known as Network Management one finds that the data we need to manage is described in what we call MIBs. Long story short, one of the entries to the MIB is a counter keep track of the number of TCP segments arriving to a given system. This counter was initially designed in the 90s and the designers though that a $32$-bit variable would be able to keep track of these arrivals during a reasonable amount of time. It turns out that, as the Internet evolved and computers got faster this counter would overflow in roughly an hour. No surprise when we can hit $1$ million incoming segments per second. If you think about the numbers it's crazy... We have about $0xFFFFFFFF$ segments coming to us in such a short window of time... Given this scenario, the designers opted to up the size of the counter to $64$-bits to solve the problem. The bottom line is that even though we will not pay too much attention to this phenoma it's a very common "real world" problem. By the way, you can read up on this in RFC 4022 page $18$.

          \section{The rest of the family: other common C operators}
            \subsection{Value modification}
              Now that we have seen some basic arithmetic operations we will see how to "compress" them so that our code is smaller and easier to read. It is quite common when programming to find situations where you have to modify a variable by a given number. That is, you may need to add $5$ to variable $a$ for instance. With what we know we could carry this out with the following code:

              \begin{minted}{c}
                int a = 0; // We declare the variable
                a = a + 5; // Now a = 5!
              \end{minted}

              Now, this code is very \textit{explicit}, that is, it is telling the reader exactly what it does. Now, consider this other version of the program doing exactly the same:

              \begin{minted}{c}
                int a = 0;
                a += 5; // a = 5 too!
              \end{minted}

              This version is the shorthand notation for the one we wrote first. As you might expect, this is applicable to every basic arithmetic operator we have seen. This can be shown with:

              \begin{minted}{c}
                int a = 10;
                a -= 5; // a = 5
                int b = 10;
                b *= 0.2; // b = 5
                int c = 10;
                c /= 2; // c = 5
              \end{minted}

              All of the above would yield $5$. But wait, there is more. There is one modification that is so common it "got" its own name. That is the increment and decrement by $1$ and can be expressed as:

              \begin{minted}{c}
                int a = 4;
                a++; // a = 5
                int b = 6;
                b--; // b = 5
                int c = 4;
                ++c; // c = 5
                int d = 6;
                --d; // d = 5
              \end{minted}

              If you are wandering why we placed the "++" and the "--" both before and after the variable name don't you worry. It has to do with operator precedence and we are going to close the chapter with that topic. We would like to point out that the C++ received the name from this operator. As C++ is seen as an improvement on C its creator decided to call it C++, which literally translates into "C plus one". Whou would have though?

            \subsection{The modulo operator}
              You might remember we talked about the \textit{modulo} operator when discussing overflow. This operator \textit{returns} the remainder of the division of its operands and is denoted with the percentaje sign \%. An example will clarify it right away:

              \begin{minted}{c}
                int a = 5;
                int b = 5 % a; // b = 0
                int c = 4 % a; // c = 4
                int d = 3 % a; // d = 3
                int e = 2 % a; // e = 2
                int f = 1 % a; // f = 1
                int g = 0 % a; // g = 0
              \end{minted}

              This operation supports the shorthand notation we discussed about earlier too:

              \begin{minted}{c}
                int a = 10;
                a %= 15; // a = 10
              \end{minted}

              And now, what is this used for? If you examine the first "program" we have written you will see tht performing a modulo operation with a value $x$ will yield results in the range $[0,\ x - 1]$. This is in fact the same principle we saw with overflowing, the only thing is that instead of overflowing due to the size limitiations of our data type we are "setting" an overflow threshold with our second operand. Remember how we told you that when assigning a value $x$ to an \textit{unsigned char} we were actually assigning the value $x\ \%\ 256$? This module is imposed by the finite space we have for assigning this piece of information. Modules are commonly employed when looping thorugh an array with a counter that's always increasing for example. You can come back to this line after we touch on arrays.

            \subsection{Bit Level Operators}
              If there is one thing to be clear on is that C is not a high level language. It "is" if you comparing with assembly (asm), but when putting it up against others like Java or Python we can clearly see we are in another context. This situation will make C a common language when developing hardware and so we need to be able to manipulate bits in an easy and syntactically efficient manner. This is where what we will call the "bit level operators" come in.

              \subsection{Shifting operator}
                Shifting is rather a common operation when dealing with binary numbers. You may state that every number we work with is acctually represented in binary, it's what computers understand. The thing is that in digital electronic systems, for example, the I/O ports are actually 32-bit numbers where each bit controls an specific input. Handling these values with decimal arithmetic would be a nasty nightmare, so we instead handle them with hex numbers. When we have the "binary mindset" of an electronics person we like to talk about shifting bits rather than multiplying or dividing them. We are going to show that shifting right or left and multiplying or dividing a number by $2$, respectively, are essentially the same thing.

                As we have seen in the appendix, the value of a natural binary number is given by:

                $$\sum_{i = 0}^{n - 1} bit_i \cdot 2^{i}$$

                Notice how $n$ is our number of bits. We are going to deal with small numbers so that we don't get lost in the binary jungle \dots Let our binary number $X_b$ have $4$ bits. We can see how $X$ will be in the range $[0000,\ 1111]_b = [0, 15]_d$. Now, what shifting does is it moves each bit to the right or left and introduces $0$s either in the LSBs if shifting left or in the MSBs if shifting right.

                Let's see what a shift looks like on our guinea pig of a number. If we shift $X$ two positions to the left we would have the following. Please note that the final sub-index symbolizes the "step" of the procedure: $X_0 = 0010;\ X_1 = 0100;\ X_2 = 1000$. The values of the initial and final values would then be:

                $$Value(X_0) = \sum_{i = 0}^{4 - 1} bit_i \cdot 2^{i} = 0 \cdot (2^{0} + 2^{2} + 2^{3}) + 1 \cdot 2^{1} = 2$$
                $$Value(X_2) = \sum_{i = 0}^{4 - 1} bit_i \cdot 2^{i} = 0 \cdot (2^{0} + 2^{1} + 2^{2}) + 1 \cdot 2^{3} = 8$$

                Now, notice that:

                $$Value(X_2) = 2^{2} \cdot Value(X_0) = 2^{2} \cdot 1 \cdot 2^{1} = 2^{2 + 1} = 2^3$$

                We can also see that if we had decided to shift three positions to the left we would have needed a fifth digit. This would have provoked an overflow because the number we where intending to represent wouldn't fit in the $4$ available bits we have...

                The idea is the same for right shifting, the only thing is that we will now be dividing by $2$ with each position we shift. Let's go through an example. Take $X = 0100$ and shift it to the right twice. You will get $X_0 = 0100;\ X_1 = 0010;\ X_2 = 0001$. We can also show, just like we did before, that for right shifting the following holds: $Value(X_2) = 2^{-2} \cdot Value(X_0)$. Please remember that $\alpha \cdot 2^{-n} = \frac{\alpha}{2^n}$.

                Now, if we had shifted $4$ positions we would have experienced truncation too. Imagine we had $X = 1_b = 1_d$. If we shift it right once we see that it is equivalent to dividing it by $2$ and $1_d / 2 = 0,5$... We are dealing with \textbf{INT}egers, so we have no way of keeping track of that decimal part. Thus, the result of that operation would be $0$. This is why shifting $X = 1000$ $4$ times to the right would yield $X = 0_d$ instead of $X = 0,5_d$ \dots

                Don't worry if the above is a little bit fuzzy... We haveincluded it for the sake of completeness, but this will not usually be deat with in our "academic" context.

                Okay, enough maths for today. How do we represent a shifting operation in C? The operators are "<<" and ">>" for a left and right shift respectively. An example of them in action would be:

                \begin{minted}{c}
                  int a = 0x4; // Binary number 0..0001
                  int b = a << 2; // b = 4 * 2^2 = 16 (It fits in an int!)
                  int c = a >> 2; // c = 4 * 2^(-2) = 1
                  int d = a >> 3; // d = 0... We have truncated the value!
                \end{minted}

                We can also use the shorthand notation:

                \begin{minted}{c}
                  int a = 0x4;
                  a <<= 2; //a = 16
                \end{minted}

                Now that we have dealt with the notation, we can condense the mathematical notation we had before and give two nice expressions:

                $$X << \alpha = X \cdot 2^{\alpha}\ if\ the\ host\ variable\ is\ big\ enough$$
                $$X >> \alpha = \frac{X}{2^\alpha}\ if\ we\ have\ no\ truncation$$

              \subsection{Bitwise logical operations}




\end{document}
